---
title: "Inter-uni Datathon"
date: last-modified
author: "SUDATA Team 2"
format: 
  html: 
    number_sections: yes
    theme: flatly
    embed-resources: true
    code-fold: true
    code-tools: true
table-of-contents: true
number-sections: true
---

# Introduction

The main bulk of the code is data cleaning, and then the model was made (xgboost). All the cleaning that was applied to the training dataset has to also be applied to the test dataset. The data cleaning included some ad-hoc methods in r that we knew existed in Python, but didn't quite know if it existed in r.

### Libraries

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
library(xgboost)
library(tidyverse)
library(visdat)
library(xgboost)
library(naivebayes)
library(janitor)
library(gt)
library(caret)
library(MLmetrics)
```

### Importing Data

Note - when I imported the data, the organisers had made a slight error, and had train as test, and test as train, so I just swapped the names around and it was fine.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
train = read.csv("inter-uni-datathon-2024-nsw/test.csv")
test = read.csv("inter-uni-datathon-2024-nsw/train.csv")
```

# Data Cleaning

### Gender

This is the first of my ad-hoc methods. In python, I would use a dictionary of replacements. However, r doesn't have dictionaries (that I know of), so I used a quick loop. Of course, all code is duplicated for train and test. There are only 8 unique values, so this code just pools them into 2 categories: "Male" and "Female".
```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}

test_labs_for_later = test$TransactionNumber

male_replacements = c("isnotfemale", "Male", "man", "he")
female_replacements = c("Female", "fem", "she", "woman")

train$TransactionDate = weekdays(as.Date(train$TransactionDate))
test$TransactionDate = weekdays(as.Date(test$TransactionDate))

for(i in 1:nrow(train)){
  if(train$Gender[i] %in% male_replacements){
    train$Gender[i] = "Male"
  } else {train$Gender[i] = "Female"}
}

for(i in 1:nrow(test)){
  if(test$Gender[i] %in% male_replacements){
    test$Gender[i] = "Male"
  } else {test$Gender[i] = "Female"}
}
```

### Time

First we delete some useless columns. Latitude and Longitude data is pretty much contained in Location anyway, so there's no need to include it. Email Domain is also encoded in UserID, so can be deleted for the same reason.  
As for time: first delete AM or PM, it's all in 24 hour time anyway. Change all the "/" characters to ":", and then use some substrings to extract hours, minutes, seconds and convert it to minutes after midnight.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
#Delete useless columns
train = subset(train, select = -c(Latitude, Longitude, EmailDomain))
test = subset(test, select = -c(Latitude, Longitude, EmailDomain))


#Convert Transaction Time to minutes after midnight
train$TransactionTime = gsub("/", ":", train$TransactionTime)
train$TransactionTime = substring(train$TransactionTime, 1, 8)

test$TransactionTime = gsub("/", ":", test$TransactionTime)
test$TransactionTime = substring(test$TransactionTime, 1, 8)

train$TransactionTime = as.numeric(substring(train$TransactionTime, 1, 2))*60 +
  as.numeric(substring(train$TransactionTime, 4, 5)) +
  as.numeric(substring(train$TransactionTime, 7, 8))*(1/60)

test$TransactionTime = as.numeric(substring(test$TransactionTime, 1, 2))*60 +
  as.numeric(substring(test$TransactionTime, 4, 5)) +
  as.numeric(substring(test$TransactionTime, 7, 8))*(1/60)
```

### Working With Money

The only currencies used are AUD, AU (which is the same as AUD), AED and GBP. In each column that uses money, I use grepl to search for that specific currency in the data, and then use a currency exchange rate to convert it to AUD if necessary.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
train$Income = parse_number(train$Income)
test$Income = parse_number(test$Income)

#Expenditure all in the same currency
train$Expenditure[grepl("AUD", train$Expenditure)] = parse_number(train$Expenditure)
train$Expenditure[grepl("AU", train$Expenditure)] = parse_number(train$Expenditure)
train$Expenditure[grepl("AED", train$Expenditure)] = parse_number(train$Expenditure)*0.4
train$Expenditure = as.numeric(train$Expenditure)

test$Expenditure[grepl("AUD", test$Expenditure)] = parse_number(test$Expenditure)
test$Expenditure[grepl("AU", test$Expenditure)] = parse_number(test$Expenditure)
test$Expenditure[grepl("AED", test$Expenditure)] = parse_number(test$Expenditure)*0.4
test$Expenditure = as.numeric(test$Expenditure)

#Gift Transaction
train$GiftsTransaction[grepl("£", train$GiftsTransaction)] = parse_number(train$GiftsTransaction)*1.96
train$GiftsTransaction[grepl("GBP", train$GiftsTransaction)] = parse_number(train$GiftsTransaction)*1.96
train$GiftsTransaction[grepl("AUD", train$GiftsTransaction)] = parse_number(train$GiftsTransaction)
train$GiftsTransaction[grepl("AU", train$GiftsTransaction)] = parse_number(train$GiftsTransaction)
train$GiftsTransaction = as.numeric(train$GiftsTransaction)

test$GiftsTransaction[grepl("£", test$GiftsTransaction)] = parse_number(test$GiftsTransaction)*1.96
test$GiftsTransaction[grepl("GBP", test$GiftsTransaction)] = parse_number(test$GiftsTransaction)*1.96
test$GiftsTransaction[grepl("AUD", test$GiftsTransaction)] = parse_number(test$GiftsTransaction)
test$GiftsTransaction[grepl("AU", test$GiftsTransaction)] = parse_number(test$GiftsTransaction)
test$GiftsTransaction = as.numeric(test$GiftsTransaction)

#Transaction Amount
train$TransactionAmount[grepl("AUD", train$TransactionAmount)] = parse_number(train$TransactionAmount)
train$TransactionAmount[grepl("AU", train$TransactionAmount)] = parse_number(train$TransactionAmount)
train$TransactionAmount[grepl("AED", train$TransactionAmount)] = parse_number(train$TransactionAmount)*0.4
train$TransactionAmount = as.numeric(train$TransactionAmount)

test$TransactionAmount[grepl("AUD", test$TransactionAmount)] = parse_number(test$TransactionAmount)
test$TransactionAmount[grepl("AU", test$TransactionAmount)] = parse_number(test$TransactionAmount)
test$TransactionAmount[grepl("AED", test$TransactionAmount)] = parse_number(test$TransactionAmount)*0.4
test$TransactionAmount = as.numeric(test$TransactionAmount)
```

### Location

This is a similar method to what we did with gender: look at all the unique values, make a replacements dictionary and search through the data replacing misspelled locations with their proper abbreviation. Again in python a dictionary would work well and handle this quite quickly (with 2 for loops); in r I don't have a dictionary so I just hada to do it the old-fashioned way.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}

adl_rep = c("ADL","ADELAIDE","ADELAIDE CITY")
syd_rep = c("SYD", "SYDNEY")
mlb_rep = c("MLB", "MELB", "MEL", "MELBURN", "MELBOURNE")
brs_rep = c("BNE", "BRISBANE" )
hb_rep = c("HOBART", "HBT")
pth_rep = c("PTH", "PERTH")
cb_rep = c("CANBERRA", "CBR")
dw_rep = c("DARWIN", "DRW")

train$TransactionLocation = toupper(train$TransactionLocation)
for(i in 1:nrow(train)){
  if(train$TransactionLocation[i] %in% adl_rep){
    train$TransactionLocation[i] = "ADL"
  } else if (train$TransactionLocation[i] %in% syd_rep){
    train$TransactionLocation[i] = "SYD"
  }else if (train$TransactionLocation[i] %in% mlb_rep){
    train$TransactionLocation[i] = "MLB"
  }else if (train$TransactionLocation[i] %in% brs_rep){
    train$TransactionLocation[i] = "BRS"
  }else if (train$TransactionLocation[i] %in% hb_rep){
    train$TransactionLocation[i] = "HB"
  }else if (train$TransactionLocation[i] %in% pth_rep){
    train$TransactionLocation[i] = "PTH"
  }else if (train$TransactionLocation[i] %in% cb_rep){
    train$TransactionLocation[i] = "CB"
  }else if (train$TransactionLocation[i] %in% dw_rep){
    train$TransactionLocation[i] = "DRW"
  }
}

test$TransactionLocation = toupper(test$TransactionLocation)
for(i in 1:nrow(test)){
  if(test$TransactionLocation[i] %in% adl_rep){
    test$TransactionLocation[i] = "ADL"
  } else if (test$TransactionLocation[i] %in% syd_rep){
    test$TransactionLocation[i] = "SYD"
  }else if (test$TransactionLocation[i] %in% mlb_rep){
    test$TransactionLocation[i] = "MLB"
  }else if (test$TransactionLocation[i] %in% brs_rep){
    test$TransactionLocation[i] = "BRS"
  }else if (test$TransactionLocation[i] %in% hb_rep){
    test$TransactionLocation[i] = "HB"
  }else if (test$TransactionLocation[i] %in% pth_rep){
    test$TransactionLocation[i] = "PTH"
  }else if (test$TransactionLocation[i] %in% cb_rep){
    test$TransactionLocation[i] = "CB"
  }else if (test$TransactionLocation[i] %in% dw_rep){
    test$TransactionLocation[i] = "DRW"
  }
}
```

### Device Type

Just pooling values to what they actually mean (most of them are just mobile phones). Fun fact; I misspelled iphone 15 as "Iphone 15" and didn't find it for ages.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
train$DeviceType[train$DeviceType == "mob"] = "Mobile"
train$DeviceType[train$DeviceType == "iphone 15"] = "Mobile"
train$DeviceType[train$DeviceType == "smartphone"] = "Mobile"
train$DeviceType[train$DeviceType == "galaxys7"] = "Mobile"
train$DeviceType[train$DeviceType == "Tablet"] = "Mobile"

test$DeviceType[test$DeviceType == "mob"] = "Mobile"
test$DeviceType[test$DeviceType == "iphone 15"] = "Mobile"
test$DeviceType[test$DeviceType == "smartphone"] = "Mobile"
test$DeviceType[test$DeviceType == "galaxys7"] = "Mobile"
test$DeviceType[test$DeviceType == "Tablet"] = "Mobile"
```

### Age

There were a few weird values in age. Most of them just looked like typos (e.g. 20 was input as 20,000). This just filters for weird values and converts them to what they should properly be.  

Finally, the data is ready to be exported as a clean csv for the group to work on.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
train$Age[train$Age >1000] = train$Age/1000
train$Age[train$Age < 1 & train$Age > 0] = train$Age[train$Age < 1 & train$Age > 0] * 1000
train$Age[train$Age <0] = abs(train$Age)

test$Age[test$Age >1000] = test$Age/1000
test$Age[test$Age < 1 & test$Age > 0] = test$Age[test$Age < 1 & test$Age > 0] * 1000
test$Age[test$Age <0] = abs(test$Age)

write.csv(train, "actual_clean_train.csv",row.names = FALSE)
write.csv(test, "actual_clean_test.csv", row.names=FALSE)

```

# Model

## One-hot encoding

For the xgboost model, all the data has to be numeric. Thankfully, the categorical variables didn't have too many levels, so it wouldn't make a crazy sparse matrix.  
Again I'm aware that there is probably a better way to do this with a loop, but it's easier this way with some copying and pasting. At the end of this code block, bind all of the one-hot matrices into the original dataframes, and drop the original categories.
```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
fraud_labels = train$IsFraud
train = subset(train, select = -IsFraud)


new_gender = model.matrix(~Gender-1, train)
new_occupation = model.matrix(~Occupation-1, train)
new_education = model.matrix(~EducationLevel-1, train)
new_marital = model.matrix(~MaritalStatus-1, train)
new_merchant = model.matrix(~MerchantID-1, train)
new_transaction = model.matrix(~TransactionType-1, train)
new_location = model.matrix(~TransactionLocation-1, train)
new_device = model.matrix(~DeviceType-1, train)
new_terrorism = model.matrix(~Terrorism-1, train)

train = cbind(train, new_gender, new_occupation, new_education, new_marital, new_merchant, new_transaction, new_location, new_device, new_terrorism)
train = subset(train, select = -c(Gender, Occupation, EducationLevel, MaritalStatus, MerchantID, TransactionType, TransactionLocation, DeviceType, Terrorism))

new_gender = model.matrix(~Gender-1, test)
new_occupation = model.matrix(~Occupation-1, test)
new_education = model.matrix(~EducationLevel-1, test)
new_marital = model.matrix(~MaritalStatus-1, test)
new_merchant = model.matrix(~MerchantID-1, test)
new_transaction = model.matrix(~TransactionType-1, test)
new_location = model.matrix(~TransactionLocation-1, test)
new_device = model.matrix(~DeviceType-1, test)
new_terrorism = model.matrix(~Terrorism-1, test)

test = cbind(test, new_gender, new_occupation, new_education, new_marital, new_merchant, new_transaction, new_location, new_device, new_terrorism)
test = subset(test, select = -c(Gender, Occupation, EducationLevel, MaritalStatus, MerchantID, TransactionType, TransactionLocation, DeviceType, Terrorism))
```

## Converting to DMatrix

Some simple code that converts the data frames into DMatrix format for the model to use.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
train = data.matrix(train)
fraud_labels = data.matrix(fraud_labels)
test = data.matrix(test)

dtrain = xgb.DMatrix(train, label = fraud_labels)
dtest = xgb.DMatrix(test)

```

## Bootstrapping/Hyperparameters

Here the hyperparameters are set up for the model. Sample rate is how much of the training set we use for our training each eopch.  
A nice technique is using a vector of probabilities. Each training example is given equal probability to begin. If the model incorrectly classifies that training example, the probability for that specific example increases. This means that next time it is more likely to be used in the training data.


### Why Epochs?

Every epoch, we train the data on a different portion of the training set, and use that (slightly) smaller model to make predictions. At the end, for each example we just take the majority vote for predicitons. This means we get a suite of models that are well-rounded and understand the dataset in different ways. This (should) give us a better overall output.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
sample_rate = 0.9
epochs = 10
low_threshold = 0
set.seed(123)

actual_results = numeric(nrow(dtest))
accuracy = 0
probabilities = rep(1/nrow(dtrain), nrow(dtrain))
```

## Running the model

Everything is put together here. train_indicies are got by sampling ("with replacement" as another hyperparameter). The accuracy and confusion matrix are calculated on the remaining data that we didn't use for the training model. At the end , we make our actual predictions by dividing by the number of epochs and rounding to get 0s or 1s.

```{r, tidy=TRUE, results='hide', results='hold', warning = FALSE, message = FALSE}
for(i in 1:epochs){
  probabilities = probabilities/sum(probabilities)
  
  
  train_indicies = sample(1:nrow(train), floor(sample_rate * nrow(train)), replace = FALSE, prob = probabilities)
  train1 = train[train_indicies,]
  test1 = fraud_labels[train_indicies]
  
  train2 = train[-train_indicies,]
  test2 = fraud_labels[-train_indicies]
  
  model = xgboost(data = dtrain, nround = 1, objective = "binary:logistic")
  
  practice_preds = predict(model, train2)

  incorrect_indices = which(round(practice_preds) != test2)
  
  test_indicies = setdiff(1:nrow(train), train_indicies)
  incorrects = test_indicies[incorrect_indices]
  
  probabilities[incorrects] = 4*probabilities[incorrects]


  accuracy = accuracy + (sum(round(practice_preds) == test2)/length(test2))
  conf = confusionMatrix(data=as.factor(round(practice_preds)), reference = as.factor(test2))
  print(conf)
  print(F1_Score(round(practice_preds), test2))

  if(i>=low_threshold){
    actual_predicts = predict(model, dtest)
    actual_results = actual_results + actual_predicts
  }
}

actuals = (round(actual_results/(epochs-low_threshold)))

results = data.frame(TransactionNumber = test_labs_for_later, IsFraud = actuals)
write.csv(results, file = "xgboost.csv", row.names = FALSE)

```

